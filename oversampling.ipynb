{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Helper-Functions-(Will-be-migrated-to-utils)\" data-toc-modified-id=\"Helper-Functions-(Will-be-migrated-to-utils)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Helper Functions (Will be migrated to utils)</a></span></li><li><span><a href=\"#Performance-Comparison\" data-toc-modified-id=\"Performance-Comparison-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Performance Comparison</a></span><ul class=\"toc-item\"><li><span><a href=\"#Oversampling\" data-toc-modified-id=\"Oversampling-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Oversampling</a></span></li><li><span><a href=\"#Under-&amp;-Oversampling\" data-toc-modified-id=\"Under-&amp;-Oversampling-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Under &amp; Oversampling</a></span></li></ul></li><li><span><a href=\"#Analysis\" data-toc-modified-id=\"Analysis-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Analysis</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n",
      "Added 1048 patients\n"
     ]
    }
   ],
   "source": [
    "# from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "# Environment Setup\n",
    "from utils import *\n",
    "from setup import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6a115dfddf45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "train_pids = train_data['Unnamed: 0'].values\n",
    "test_pids = test_data['Unnamed: 0'].values\n",
    "\n",
    "train_y = train_data['BIRADS'].values\n",
    "train_y_bi = np.where(train_y>3,1,0)\n",
    "train_data = train_data.drop(columns=['BIRADS', 'Unnamed: 0'])\n",
    "\n",
    "test_y = test_data['BIRADS'].values\n",
    "test_y_bi = np.where(test_y>3,1,0)\n",
    "test_data = test_data.drop(columns=['BIRADS', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test_y_bi)/len(test_y_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions (Will be migrated to utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(X, y):\n",
    "    \"\"\"\n",
    "    Perform t-sne using the resampled data (can be done\n",
    "    without augmented data) and blind data.\n",
    "    \"\"\"\n",
    "    x = X.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    X_norm = pd.DataFrame(x_scaled)\n",
    "\n",
    "    tsne = TSNE(n_components=2,\n",
    "                 init='random',\n",
    "                 learning_rate=5,\n",
    "                 random_state=1,\n",
    "                 perplexity=30,\n",
    "                 early_exaggeration=20,\n",
    "                 n_iter=2000,\n",
    "                 metric='euclidean',\n",
    "                 angle=0.2)\n",
    "\n",
    "    y_tsne = tsne.fit_transform(X_norm)\n",
    "\n",
    "\n",
    "    green = y == 0\n",
    "    red = y == 1\n",
    "\n",
    "    plt.scatter(y_tsne[green, 0], y_tsne[green, 1], c=\"g\", alpha = 0.3, label='Healthy')\n",
    "    plt.scatter(y_tsne[red, 0], y_tsne[red, 1], c=\"r\", alpha = 0.5, label='Cancer')\n",
    "    plt.axis('off')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_tsne_birads(X, y, X_blind, y_blind, train_mean, train_std):\n",
    "    \"\"\"\n",
    "    Perform t-sne using the resampled data (can be done\n",
    "    without augmented data) and blind data.\n",
    "    \"\"\"\n",
    "    X_norm = (X - train_mean)/train_std\n",
    "    X_blind_norm = (X_blind - train_mean)/train_std\n",
    "    \n",
    "    y_stack = np.append(y, y_blind)\n",
    "    one = y_stack == 1\n",
    "    two = y_stack == 2\n",
    "    three = y_stack == 3\n",
    "    four = y_stack == 4\n",
    "    five = y_stack == 5\n",
    "    six = y_stack == 6\n",
    "    unlabelled= y_stack == -1\n",
    "\n",
    "    tsne = TSNE(n_components=2,\n",
    "                 init='random',\n",
    "                 learning_rate=5,\n",
    "                 random_state=1,\n",
    "                 perplexity=30,\n",
    "                 early_exaggeration=20,\n",
    "                 n_iter=2000,\n",
    "                 metric='euclidean',\n",
    "                 angle=0.2)\n",
    "\n",
    "    y_tsne = tsne.fit_transform(np.vstack([X_norm, X_blind_norm]))\n",
    "    plt.scatter(y_tsne[one, 0], y_tsne[one, 1], c=\"g\", alpha = 0.3, label='1')\n",
    "    plt.scatter(y_tsne[two, 0], y_tsne[two, 1], c=\"g\", alpha = 0.3, label='2')\n",
    "    plt.scatter(y_tsne[three, 0], y_tsne[three, 1], c=\"yellow\", alpha = 0.5, label='3')\n",
    "    plt.scatter(y_tsne[four, 0], y_tsne[four, 1], c=\"magenta\", alpha = 0.5, label='4')\n",
    "    plt.scatter(y_tsne[five, 0], y_tsne[five, 1], c=\"blue\", alpha = 0.5, label='5')\n",
    "    plt.scatter(y_tsne[six, 0], y_tsne[six, 1], c=\"red\", alpha = 0.5, label='6')\n",
    "    plt.scatter(y_tsne[unlabelled, 0], y_tsne[unlabelled, 1], c=\"g\", alpha = 0.1, label='-1')\n",
    "    plt.legend()\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "def performance(X, y, X_test, y_test, detailed = False, title=''):\n",
    "    \n",
    "    \"\"\" Obtain tuned LogReg model classification performance.\n",
    "    \n",
    "\n",
    "    Inputs\n",
    "    ----------\n",
    "    X: dataframe or numpy array\n",
    "         training set with features\n",
    "    y: np.array\n",
    "         training targets    \n",
    "    X_test: dataframe or numpy array\n",
    "         test set with features\n",
    "    y_test: np.array\n",
    "         test targets    \n",
    "\n",
    "    detailed: bool\n",
    "         Indicates whether to print a detailed\n",
    "         report and ROC curve or not\n",
    "    title: str\n",
    "         A title that is given to the ROC\n",
    "         curve plot and the AUC score\n",
    "        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    AUC score for a specific technique\n",
    "    Optional\n",
    "    \"\"\"\n",
    "# Use basic logreg instead of pretrained model\n",
    "#     exec(compile(open('src/models/classifiers/LogReg.py').read(), \n",
    "#                  'src/models/classifiers/LogReg.py', 'exec'), globals())\n",
    "    clf = LogReg.model\n",
    "    # Make sure I dont use pre-tuned model for feature evaluation\n",
    "#     print('Tuned parameters: ', clf.get_params())\n",
    "    clf.fit(X, y)\n",
    "    probs = clf.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "#     print(\"AUC score: \" + title, auc(fpr,tpr))\n",
    "    if detailed: \n",
    "        plt.plot(fpr, tpr)\n",
    "\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "        report_performance(y_test, probs)\n",
    "    return(auc(fpr,tpr))\n",
    "\n",
    "\n",
    "def plot_AUC(aucs, title=''):\n",
    "    '''Plot a set of AUC scores.\n",
    "\n",
    "    Inputs\n",
    "    ----------\n",
    "    aucs: list\n",
    "         list of AUC scores\n",
    "    max_comp: int\n",
    "         maximum number of components \n",
    "    title: str\n",
    "         A title that is given to the plot\n",
    "        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Plot of AUC values\n",
    "    Maximum AUC score\n",
    "    '''\n",
    "    plt.plot(np.arange(0.1, 1.0, 0.1),aucs)\n",
    "    plt.xlabel('Float Value')\n",
    "    plt.ylabel('AUC Score')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    print('Max AUC: ', max(aucs))\n",
    "\n",
    "    \n",
    "def plot_AUCs(method, X, X_test, y_bi, y_t, label):\n",
    "    '''Plot a set of AUC scores for a specific set.\n",
    "\n",
    "    Inputs\n",
    "    ----------\n",
    "    max_comp: int\n",
    "         maximum number of components \n",
    "    X_train: dataframe or numpy array\n",
    "         training set with reduced features\n",
    "    X_test: dataframe or numpy array\n",
    "         test set with reduced features\n",
    "    y_train: np.array\n",
    "         training targets    \n",
    "    y_test: np.array\n",
    "         test targets  \n",
    "    label: str\n",
    "         A title that is given to the plot\n",
    "    best: bool\n",
    "        Whether to pick features with best t-values\n",
    "    stats: dataframe\n",
    "        Output of the get_stats function\n",
    "        \n",
    "\n",
    "    Output\n",
    "    -------\n",
    "    Plot of AUC values\n",
    "    Maximum AUC score\n",
    "    '''\n",
    "    avg_base = [performance(X, y_bi, X_test, y_t) for i in range(100)]\n",
    "    aucs = [np.mean(avg_base)]\n",
    "    for i in np.arange(0.2, 1.0, 0.1):\n",
    "        sampler = method(i)\n",
    "        avg_auc = []\n",
    "        for i in range(100):\n",
    "            X_res, y_res = sampler.fit_resample(X, y_bi)\n",
    "            avg_auc.append(performance(X_res, y_res, X_test, y_t))\n",
    "        aucs.append(np.mean(avg_auc))\n",
    "    plot_AUC(aucs, label)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn import over_sampling\n",
    "plot_AUCs(over_sampling.ADASYN, train_data, test_data, train_y_bi, test_y_bi, label='ADASYN')\n",
    "plot_AUCs(over_sampling.SMOTE, train_data, test_data, train_y_bi, test_y_bi, label='SMOTE')\n",
    "plot_AUCs(over_sampling.RandomOverSampler, train_data, test_data, train_y_bi, test_y_bi, label='Random')\n",
    "# These two methods seem to fail\n",
    "plot_AUCs(over_sampling.SVMSMOTE, train_data, test_data, train_y_bi, test_y_bi, label='SVMSMOTE')\n",
    "plot_AUCs(over_sampling.BorderlineSMOTE, train_data, test_data, train_y_bi, test_y_bi,label='BorderlineSMOTE')\n",
    "# No clusters found with sufficient samples of class 1.0 to perform these methods\n",
    "plot_AUCs(over_sampling.KMeansSMOTE, train_data, test_data, train_y_bi, test_y_bi, label='KMeansSMOTE')\n",
    "plot_AUCs(over_sampling.SMOTENC, train_data, test_data, train_y_bi, test_y_bi, label='SMOTENC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under & Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_AUCs(SMOTETomek, train_data, test_data, train_y_bi, test_y_bi,label='SMOTE & Tomek')\n",
    "# Doesn't work with the data\n",
    "# plot_AUCs(SMOTEENN, X, X_test, y_bi, y_t, label='SMOTE & ENN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color by center\n",
    "plot_tsne(train_data, train_y_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = over_sampling.ADASYN(0.5)\n",
    "X_res, y_res = sampler.fit_resample(train_data, train_y_bi)\n",
    "X_res = pd.DataFrame(X_res)\n",
    "plot_tsne(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = over_sampling.SMOTE(0.5)\n",
    "X_res, y_res = sampler.fit_resample(train_data, train_y_bi)\n",
    "X_res = pd.DataFrame(X_res)\n",
    "plot_tsne(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = over_sampling.ADASYN(0.5)\n",
    "X_res, y_res = sampler.fit_resample(X, y_bi)\n",
    "plot_tsne(X_res, y_res, X_blind, y_blind, mean_x, std_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evamodels",
   "language": "python",
   "name": "evamodels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
